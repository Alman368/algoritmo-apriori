{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis de Reglas de Asociación en Partidas de Ajedrez",
        "",
        "## Descripción del Proyecto",
        "",
        "Este notebook implementa el algoritmo Apriori para analizar patrones en partidas de ajedrez de lichess.org. Se estudian dos modalidades de juego: **ajedrez relámpago (600+0)** y **ajedrez bala (60+0)**.",
        "",
        "### Objetivos",
        "",
        "1. **Implementación del Algoritmo Apriori**: Aplicación práctica para descubrir reglas de asociación",
        "2. **Análisis de Patrones de Juego**: Identificación de relaciones entre variables categóricas",
        "3. **Verificación de Hipótesis Específicas**: Validación estadística de reglas propuestas",
        "4. **Comparación de Modalidades**: Análisis diferencial entre ritmos de juego",
        "",
        "### Metodología",
        "",
        "- **Preprocesamiento**: Limpieza y categorización de variables",
        "- **Extracción de reglas**: Aplicación de Apriori con parámetros apropiados",
        "- **Métricas de evaluación**: Cálculo de soporte, confianza y lift",
        "- **Comparación de resultados**: Visualización de resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /opt/anaconda3/lib/python3.12/site-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from mlxtend) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from mlxtend) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/lib/python3.12/site-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from mlxtend) (1.5.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlxtend) (3.9.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
            "================================================================================\n",
            "    ANÁLISIS DE REGLAS DE ASOCIACIÓN EN PARTIDAS DE AJEDREZ\n",
            "    Algoritmo Apriori - Dataset lichess.org 2013\n",
            "================================================================================\n",
            "\n",
            "✓ Entorno de análisis configurado correctamente\n",
            "✓ Librerías especializadas cargadas\n",
            "✓ Configuración de visualización establecida\n"
          ]
        }
      ],
      "source": [
        "# Instalación de librerías necesarias",
        "!pip install mlxtend",
        "",
        "# Importación de librerías necesarias",
        "import pandas as pd",
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from mlxtend.frequent_patterns import apriori, association_rules",
        "from mlxtend.preprocessing import TransactionEncoder",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "# Configuración de pandas",
        "pd.set_option('display.max_columns', None)",
        "pd.set_option('display.width', None)",
        "pd.set_option('display.max_colwidth', None)",
        "",
        "# Configuración de gráficos",
        "plt.style.use('default')",
        "sns.set_palette('husl')",
        "",
        "print('=' * 80)",
        "print('    ANÁLISIS DE REGLAS DE ASOCIACIÓN EN PARTIDAS DE AJEDREZ')",
        "print('    Algoritmo Apriori - Dataset lichess.org 2013')",
        "print('=' * 80)",
        "print('\\nLibrerías cargadas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carga y Exploración Inicial del Dataset",
        "",
        "### Características del Dataset",
        "",
        "El dataset `lichess_games_2013-01.csv` contiene información sobre partidas de ajedrez del portal lichess.org, incluyendo:",
        "",
        "- **Información de jugadores**: Nombres y puntuaciones Elo",
        "- **Características de partida**: Resultado, control de tiempo, número de movimientos",
        "- **Información técnica**: Código ECO, apertura, tipo de finalización",
        "",
        "### Proceso de Exploración",
        "",
        "Se realizará un análisis exploratorio  de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando carga del dataset...\n",
            "\n",
            " INFORMACIÓN DIMENSIONAL\n",
            "Dimensiones del dataset: 121,332 filas × 11 columnas\n",
            "Memoria utilizada: 66.91 MB\n",
            "\n",
            " INFORMACIÓN ESTRUCTURAL\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 121332 entries, 0 to 121331\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   Site         121332 non-null  object\n",
            " 1   White        121332 non-null  object\n",
            " 2   Black        121332 non-null  object\n",
            " 3   Result       121332 non-null  object\n",
            " 4   WhiteElo     121332 non-null  object\n",
            " 5   BlackElo     121332 non-null  object\n",
            " 6   TimeControl  121332 non-null  object\n",
            " 7   ECO          121332 non-null  object\n",
            " 8   Opening      121332 non-null  object\n",
            " 9   Termination  121332 non-null  object\n",
            " 10  MovesCount   121332 non-null  int64 \n",
            "dtypes: int64(1), object(10)\n",
            "memory usage: 10.2+ MB\n",
            "None\n",
            "\n",
            " INTEGRIDAD DE DATOS\n",
            "Valores faltantes por columna:\n",
            "  Site: Sin valores faltantes ✓\n",
            "  White: Sin valores faltantes ✓\n",
            "  Black: Sin valores faltantes ✓\n",
            "  Result: Sin valores faltantes ✓\n",
            "  WhiteElo: Sin valores faltantes ✓\n",
            "  BlackElo: Sin valores faltantes ✓\n",
            "  TimeControl: Sin valores faltantes ✓\n",
            "  ECO: Sin valores faltantes ✓\n",
            "  Opening: Sin valores faltantes ✓\n",
            "  Termination: Sin valores faltantes ✓\n",
            "  MovesCount: Sin valores faltantes ✓\n",
            "\n",
            "✓ Carga del dataset completada exitosamente\n"
          ]
        }
      ],
      "source": [
        "# Carga del dataset principal",
        "print('Cargando datos...')",
        "df = pd.read_csv('lichess_games_2013-01.csv')",
        "",
        "# Análisis del dataset",
        "print(f'\\n INFORMACIÓN DIMENSIONAL')",
        "print(f'Dimensiones del dataset: {df.shape[0]:,} filas × {df.shape[1]} columnas')",
        "print(f'Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')",
        "",
        "# Información estructural",
        "print(f'\\n INFORMACIÓN ESTRUCTURAL')",
        "print(df.info())",
        "",
        "# Valores faltantes",
        "print(f'\\n INTEGRIDAD DE DATOS')",
        "print('Valores faltantes por columna:')",
        "missing_data = df.isnull().sum()",
        "for col, missing in missing_data.items():",
        "    if missing > 0:",
        "        percentage = (missing / len(df)) * 100",
        "        print(f'  {col}: {missing:,} ({percentage:.2f}%)')",
        "    else:",
        "        print(f'  {col}: Sin valores faltantes')",
        "",
        "print('\\nDataset cargado')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocesamiento y Categorización de Variables",
        "",
        "### Tratamiento de Valores Especiales",
        "",
        "Se realizará la limpieza de datos siguiendo las especificaciones del proyecto:",
        "- Conversión de valores \"?\" en Elo a 900 puntos",
        "- Categorización de Elo según rangos estándar",
        "- Categorización de número de movimientos por duración",
        "",
        "### Sistema de Categorización",
        "",
        "**Categorías de Elo:**",
        "- Principiante: 0-1199",
        "- Intermedio: 1200-1599",
        "- Avanzado: 1600-1999",
        "- Experto: 2000-2399",
        "- Maestro: 2400-2799",
        "- Gran Maestro: 2800+",
        "",
        "**Categorías de Duración:**",
        "- Corta: <20 movimientos",
        "- Media: 20-39 movimientos",
        "- Larga: 40-59 movimientos",
        "- Muy larga: 60+ movimientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " INICIANDO PREPROCESAMIENTO DE DATOS\n",
            "\n",
            "1. Tratamiento de valores Elo...\n",
            "   Valores \"?\" en WhiteElo: 78\n",
            "   Valores \"?\" en BlackElo: 140\n",
            "   ✓ Conversión de Elo completada (\"?\" → 900)\n",
            "   Rango WhiteElo: 782 - 2403\n",
            "   Rango BlackElo: 789 - 2386\n"
          ]
        }
      ],
      "source": [
        "# Creación de copia para procesamiento",
        "print(' INICIANDO PREPROCESAMIENTO DE DATOS')",
        "df_processed = df.copy()",
        "",
        "# Tratamiento de valores especiales en Elo",
        "print('\\n1. Tratamiento de valores Elo...')",
        "print(f'   Valores \"?\" en WhiteElo: {(df_processed[\"WhiteElo\"] == \"?\").sum():,}')",
        "print(f'   Valores \"?\" en BlackElo: {(df_processed[\"BlackElo\"] == \"?\").sum():,}')",
        "",
        "# Reemplazar \"?\" por 900 según especificaciones",
        "df_processed['WhiteElo'] = df_processed['WhiteElo'].replace('?', '900')",
        "df_processed['BlackElo'] = df_processed['BlackElo'].replace('?', '900')",
        "df_processed['WhiteElo'] = pd.to_numeric(df_processed['WhiteElo'], errors='coerce')",
        "df_processed['BlackElo'] = pd.to_numeric(df_processed['BlackElo'], errors='coerce')",
        "",
        "# Imputación de valores faltantes",
        "df_processed['WhiteElo'].fillna(900, inplace=True)",
        "df_processed['BlackElo'].fillna(900, inplace=True)",
        "",
        "print('   Conversión de Elo realizada (\"?\" → 900)')",
        "print(f'   Rango WhiteElo: {df_processed[\"WhiteElo\"].min():.0f} - {df_processed[\"WhiteElo\"].max():.0f}')",
        "print(f'   Rango BlackElo: {df_processed[\"BlackElo\"].min():.0f} - {df_processed[\"BlackElo\"].max():.0f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "2. Aplicando sistema de categorización...\n",
            "   ✓ Categorización de Elo completada\n",
            "   ✓ Categorización de movimientos completada\n",
            "\n",
            "📊 ANÁLISIS DE DISTRIBUCIONES CATEGÓRICAS\n",
            "\n",
            "Distribución WhiteElo_Cat:\n",
            "WhiteElo_Cat\n",
            "Intermedio      57571\n",
            "Avanzado        57540\n",
            "Experto          3550\n",
            "Principiante     2670\n",
            "Maestro             1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución MovesCount_Cat:\n",
            "MovesCount_Cat\n",
            "Media        61374\n",
            "Larga        29137\n",
            "Corta        21750\n",
            "Muy larga     9071\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Funciones de categorización",
        "def categorizar_elo(elo):",
        "    \"\"\"Categoriza el Elo según rangos estándar internacionales de ajedrez\"\"\"",
        "    if elo < 1200:",
        "        return \"Principiante\"",
        "    elif elo < 1600:",
        "        return \"Intermedio\"",
        "    elif elo < 2000:",
        "        return \"Avanzado\"",
        "    elif elo < 2400:",
        "        return \"Experto\"",
        "    elif elo < 2800:",
        "        return \"Maestro\"",
        "    else:",
        "        return \"Gran Maestro\"",
        "",
        "def categorizar_movimientos(moves):",
        "    \"\"\"Categoriza la duración de partidas según número de movimientos\"\"\"",
        "    if moves < 20:",
        "        return \"Corta\"",
        "    elif moves < 40:",
        "        return \"Media\"",
        "    elif moves < 60:",
        "        return \"Larga\"",
        "    else:",
        "        return \"Muy larga\"",
        "",
        "# Aplicación de categorizaciones",
        "print('\\n2. Categorizando variables...')",
        "df_processed['WhiteElo_Cat'] = df_processed['WhiteElo'].apply(categorizar_elo)",
        "df_processed['BlackElo_Cat'] = df_processed['BlackElo'].apply(categorizar_elo)",
        "df_processed['MovesCount_Cat'] = df_processed['MovesCount'].apply(categorizar_movimientos)",
        "",
        "print('   Categorización de Elo aplicada')",
        "print('   Categorización de movimientos aplicada')",
        "",
        "# Distribuciones",
        "print(f'\\n📊 ANÁLISIS DE DISTRIBUCIONES CATEGÓRICAS')",
        "print('\\nDistribución WhiteElo_Cat:')",
        "white_elo_dist = df_processed['WhiteElo_Cat'].value_counts()",
        "print(white_elo_dist)",
        "print('\\nDistribución MovesCount_Cat:')",
        "moves_dist = df_processed['MovesCount_Cat'].value_counts()",
        "print(moves_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3. Generando variables derivadas...\n",
            "   ✓ Diferencia de Elo calculada\n",
            "   ✓ Diferencia categórica calculada\n",
            "   ✓ Jugador más fuerte identificado\n",
            "\n",
            " RESUMEN DE VARIABLES DERIVADAS\n",
            "Dataset procesado: 121,332 filas × 17 columnas\n",
            "\n",
            "Nuevas variables creadas:\n",
            "- WhiteElo_Cat, BlackElo_Cat: Categorías de Elo\n",
            "- MovesCount_Cat: Categorías de duración\n",
            "- EloDiff: Diferencia absoluta de Elo\n",
            "- EloDiff_Cat: Diferencia en categorías\n",
            "- JugadorMasFuerte: Identificación de jugador dominante\n"
          ]
        }
      ],
      "source": [
        "# Variables derivadas",
        "print('\\n3. Calculando variables...')",
        "",
        "# Diferencia absoluta de Elo",
        "df_processed['EloDiff'] = abs(df_processed['WhiteElo'] - df_processed['BlackElo'])",
        "",
        "# Diferencia en categorías de Elo",
        "def diferencia_categorias_elo(white_elo, black_elo):",
        "    \"\"\"Calcula la diferencia en categorías entre jugadores\"\"\"",
        "    categorias = [0, 1200, 1600, 2000, 2400, 2800, float('inf')]",
        "    cat_names = ['Principiante', 'Intermedio', 'Avanzado', 'Experto', 'Maestro', 'Gran Maestro']",
        "",
        "    # Determinar categoría de cada jugador",
        "    white_cat_idx = next(i for i, threshold in enumerate(categorias[1:]) if white_elo < threshold)",
        "    black_cat_idx = next(i for i, threshold in enumerate(categorias[1:]) if black_elo < threshold)",
        "",
        "    return abs(white_cat_idx - black_cat_idx)",
        "",
        "# Aplicar función de diferencia categórica",
        "df_processed['EloDiff_Cat'] = df_processed.apply(",
        "    lambda row: diferencia_categorias_elo(row['WhiteElo'], row['BlackElo']), axis=1",
        ")",
        "",
        "# Jugador con mayor Elo",
        "def jugador_mas_fuerte(row):",
        "    \"\"\"Identifica qué jugador tiene mayor Elo\"\"\"",
        "    if row['WhiteElo'] > row['BlackElo']:",
        "        return 'Blanco'",
        "    elif row['BlackElo'] > row['WhiteElo']:",
        "        return 'Negro'",
        "    else:",
        "        return 'Empate'",
        "",
        "df_processed['JugadorMasFuerte'] = df_processed.apply(jugador_mas_fuerte, axis=1)",
        "",
        "print('   Diferencia de Elo calculada')",
        "print('   Diferencia categórica calculada')",
        "print('   Jugador más fuerte identificado')",
        "",
        "# Variables creadas",
        "print(f'\\n RESUMEN DE VARIABLES DERIVADAS')",
        "print(f'{df_processed.shape[0]:,} filas × {df_processed.shape[1]} columnas')",
        "print(f'\\nNuevas variables creadas:')",
        "print('- WhiteElo_Cat, BlackElo_Cat: Categorías de Elo')",
        "print('- MovesCount_Cat: Categorías de duración')",
        "print('- EloDiff: Diferencia absoluta de Elo')",
        "print('- EloDiff_Cat: Diferencia en categorías')",
        "print('- JugadorMasFuerte: Identificación de jugador dominante')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análisis del Subconjunto Ajedrez Relámpago (600+0)",
        "",
        "### Características del Ajedrez Relámpago",
        "",
        "El ajedrez relámpago con control de tiempo \"600+0\" (10 minutos sin incremento) representa un formato equilibrado entre:",
        "- **Tiempo suficiente**: Para desarrollar estrategias",
        "- **Presión temporal**: Que añade un presión de tiempo",
        "- **Popularidad**: Una de las modalidades más jugadas en plataformas online",
        "",
        "### Objetivos del Análisis",
        "",
        "1. **Caracterización del subconjunto**: Análisis descriptivo de las partidas",
        "2. **Aplicación de Apriori**: Descubrimiento de patrones frecuentes",
        "3. **Extracción de reglas**: Identificación de reglas de asociación significativas",
        "4. **Verificación de hipótesis**: Validación de reglas específicas propuestas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANÁLISIS DE AJEDREZ RELÁMPAGO (600+0)\n",
            "============================================================\n",
            "\n",
            " ESTADÍSTICAS DEL SUBCONJUNTO RELÁMPAGO\n",
            "Control de tiempo analizado: 600+0\n",
            "Número de partidas: 2,452\n",
            "Porcentaje del dataset total: 2.02%\n",
            "\n",
            " DISTRIBUCIÓN DE RESULTADOS\n",
            "  1-0: 1,206 partidas (49.2%)\n",
            "  0-1: 1,174 partidas (47.9%)\n",
            "  1/2-1/2: 72 partidas (2.9%)\n",
            "\n",
            "⚡ CARACTERÍSTICAS TEMPORALES\n",
            "Elo promedio blancas: 1553\n",
            "Elo promedio negras: 1552\n",
            "Movimientos promedio: 32.9\n",
            "Diferencia Elo promedio: 145\n"
          ]
        }
      ],
      "source": [
        "# Subconjunto ajedrez relámpago",
        "print('ANÁLISIS DE AJEDREZ RELÁMPAGO (600+0)')",
        "print('=' * 60)",
        "",
        "# Filtrar partidas con TimeControl='600+0'",
        "df_600 = df_processed[df_processed['TimeControl'] == '600+0'].copy()",
        "",
        "# Análisis de disponibilidad de datos",
        "if len(df_600) == 0:",
        "    print('  No se encontraron partidas con TimeControl=\"600+0\"')",
        "    print('\\n🔍 Analizando controles de tiempo disponibles:')",
        "    tc_counts = df_processed['TimeControl'].value_counts().head(10)",
        "    print(tc_counts)",
        "",
        "    # Seleccionar el TimeControl más representativo",
        "    most_common_tc = tc_counts.index[0]",
        "    print(f'\\n Usando el TimeControl más común: {most_common_tc}')",
        "    df_600 = df_processed[df_processed['TimeControl'] == most_common_tc].copy()",
        "else:",
        "    most_common_tc = '600+0'",
        "",
        "# Estadísticas descriptivas del subconjunto",
        "print(f'\\n ESTADÍSTICAS RELÁMPAGO')",
        "print(f'Control de tiempo: {most_common_tc}')",
        "print(f'Número de partidas: {len(df_600):,}')",
        "print(f'Porcentaje del total: {len(df_600)/len(df_processed)*100:.2f}%')",
        "",
        "if len(df_600) > 0:",
        "    print(f'\\n DISTRIBUCIÓN DE RESULTADOS')",
        "    result_dist = df_600['Result'].value_counts()",
        "    for result, count in result_dist.items():",
        "        percentage = (count / len(df_600)) * 100",
        "        print(f'  {result}: {count:,} partidas ({percentage:.1f}%)')",
        "",
        "    print(f'\\nESTADÍSTICAS PRINCIPALES')",
        "    print(f'Elo medio blancas: {df_600[\"WhiteElo\"].mean():.0f}')",
        "    print(f'Elo medio negras: {df_600[\"BlackElo\"].mean():.0f}')",
        "    print(f'Movimientos medio: {df_600[\"MovesCount\"].mean():.1f}')",
        "    print(f'Diferencia Elo media: {df_600[\"EloDiff\"].mean():.0f}')",
        "else:",
        "    print(' Datos insuficientes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Implementación del Algoritmo Apriori",
        "",
        "### Fundamentos Teóricos",
        "",
        "El algoritmo Apriori es un método fundamental en minería de datos para descubrir reglas de asociación. Utiliza el principio de que todos los subconjuntos de un conjunto frecuente también son frecuentes.",
        "",
        "### Métricas de Evaluación",
        "",
        "- **Soporte**: Frecuencia de aparición del conjunto de ítems",
        "- **Confianza**: Probabilidad condicional de ocurrencia",
        "- **Lift**: Medida de independencia estadística entre antecedente y consecuente",
        "",
        "### Preparación de Datos",
        "",
        "La implementación requiere transformar los datos categóricos en formato de transacciones binarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " EJECUTANDO APRIORI - AJEDREZ RELÁMPAGO\n",
            "======================================================================\n",
            " Preparando datos para algoritmo Apriori...\n",
            "   Variables categóricas disponibles: 7\n",
            "   Transacciones generadas: 2,452\n",
            "   Ítems promedio por transacción: 6.0\n",
            "\n",
            " Matriz de codificación: 2452 × 20\n",
            "\n",
            "  Aplicando Apriori (soporte mínimo: 0.01)\n",
            "   ✓ Conjuntos frecuentes encontrados: 873\n",
            "\n",
            " Generando reglas de asociación...\n",
            "   ✓ Reglas generadas: 9346\n",
            "\n",
            " TOP 10 REGLAS MÁS SIGNIFICATIVAS:\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            " 1. MovesCount_Cat_Muy larga, Termination_Normal → Result_1/2-1/2\n",
            "    Soporte: 0.0114 | Confianza: 0.2171 | Lift: 7.3919\n",
            "\n",
            " 2. Result_1/2-1/2 → MovesCount_Cat_Muy larga, Termination_Normal\n",
            "    Soporte: 0.0114 | Confianza: 0.3889 | Lift: 7.3919\n",
            "\n",
            " 3. Result_1/2-1/2 → MovesCount_Cat_Muy larga\n",
            "    Soporte: 0.0143 | Confianza: 0.4861 | Lift: 7.0114\n",
            "\n",
            " 4. MovesCount_Cat_Muy larga → Result_1/2-1/2\n",
            "    Soporte: 0.0143 | Confianza: 0.2059 | Lift: 7.0114\n",
            "\n",
            " 5. MovesCount_Cat_Muy larga → Result_1/2-1/2, Termination_Normal\n",
            "    Soporte: 0.0114 | Confianza: 0.1647 | Lift: 6.8451\n",
            "\n",
            " 6. Result_1/2-1/2, Termination_Normal → MovesCount_Cat_Muy larga\n",
            "    Soporte: 0.0114 | Confianza: 0.4746 | Lift: 6.8451\n",
            "\n",
            " 7. WhiteElo_Cat_Intermedio, JugadorMasFuerte_Blanco, Result_1-0, Termination_Normal → BlackElo_Cat_Principiante\n",
            "    Soporte: 0.0171 | Confianza: 0.1567 | Lift: 4.4169\n",
            "\n",
            " 8. BlackElo_Cat_Principiante → WhiteElo_Cat_Intermedio, JugadorMasFuerte_Blanco, Result_1-0, Termination_Normal\n",
            "    Soporte: 0.0171 | Confianza: 0.4828 | Lift: 4.4169\n",
            "\n",
            " 9. JugadorMasFuerte_Negro, Result_1-0, WhiteElo_Cat_Avanzado → BlackElo_Cat_Avanzado, Termination_Time forfeit\n",
            "    Soporte: 0.0151 | Confianza: 0.3458 | Lift: 4.3932\n",
            "\n",
            "10. BlackElo_Cat_Avanzado, Termination_Time forfeit → JugadorMasFuerte_Negro, Result_1-0, WhiteElo_Cat_Avanzado\n",
            "    Soporte: 0.0151 | Confianza: 0.1917 | Lift: 4.3932\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Algoritmo Apriori",
        "def preparar_datos_apriori(df_subset):",
        "    \"\"\"Prepara los datos en formato transaccional para Apriori\"\"\"",
        "    print(' Preparando datos para algoritmo Apriori...')",
        "",
        "    # Seleccionar variables categóricas relevantes",
        "    cols_categoricas = [",
        "        'Result', 'WhiteElo_Cat', 'BlackElo_Cat', 'MovesCount_Cat',",
        "        'ECO', 'Termination', 'JugadorMasFuerte'",
        "    ]",
        "",
        "    # Filtrar columnas existentes",
        "    cols_disponibles = [col for col in cols_categoricas if col in df_subset.columns]",
        "    print(f'   Variables disponibles: {len(cols_disponibles)}')",
        "",
        "    # Crear transacciones",
        "    transacciones = []",
        "    for _, row in df_subset.iterrows():",
        "        transaccion = []",
        "        for col in cols_disponibles:",
        "            if pd.notna(row[col]):",
        "                # Crear etiqueta descriptiva",
        "                if col == 'ECO' and len(df_subset) > 1000:  # Limitar ECO para datasets grandes",
        "                    continue",
        "                transaccion.append(f'{col}_{row[col]}')",
        "        transacciones.append(transaccion)",
        "",
        "    print(f'   Transacciones creadas: {len(transacciones):,}')",
        "    print(f'   Ítems por transacción: {np.mean([len(t) for t in transacciones]):.1f}')",
        "",
        "    return transacciones",
        "",
        "def ejecutar_apriori(df_subset, nombre_subset, min_support=0.01):",
        "    \"\"\"Ejecuta el algoritmo Apriori y extrae reglas de asociación\"\"\"",
        "    print(f'\\n EJECUTANDO APRIORI - {nombre_subset.upper()}')",
        "    print('=' * 70)",
        "",
        "    if len(df_subset) == 0:",
        "        print(' Datos insuficientes')",
        "        return pd.DataFrame(), pd.DataFrame()",
        "",
        "    # Preparar datos",
        "    transacciones = preparar_datos_apriori(df_subset)",
        "",
        "    # Codificación binaria",
        "    te = TransactionEncoder()",
        "    te_ary = te.fit(transacciones).transform(transacciones)",
        "    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)",
        "",
        "    print(f'\\n Matriz binaria: {df_encoded.shape[0]} × {df_encoded.shape[1]}')",
        "",
        "    # Aplicar Apriori para encontrar conjuntos frecuentes",
        "    print(f'\\n  Aplicando Apriori (soporte: {min_support})')",
        "    frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)",
        "",
        "    if len(frequent_itemsets) == 0:",
        "        print(f'  Sin conjuntos frecuentes con soporte >= {min_support}')",
        "        print('   Reduciendo umbral de soporte')",
        "        frequent_itemsets = apriori(df_encoded, min_support=min_support/2, use_colnames=True)",
        "",
        "    print(f'   Conjuntos frecuentes encontrados: {len(frequent_itemsets)}')",
        "",
        "    if len(frequent_itemsets) == 0:",
        "        return pd.DataFrame(), pd.DataFrame()",
        "",
        "    # Generar reglas de asociación",
        "    print('\\n Extrayendo reglas...')",
        "    try:",
        "        rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.1)",
        "",
        "        if len(rules) > 0:",
        "            # Ordenar por lift descendente",
        "            rules_sorted = rules.sort_values('lift', ascending=False)",
        "",
        "            print(f'   Reglas generadas: {len(rules)}')",
        "            print(f'\\n TOP 10 REGLAS MÁS SIGNIFICATIVAS:')",
        "            print('-' * 120)",
        "",
        "            for i, (_, rule) in enumerate(rules_sorted.head(10).iterrows(), 1):",
        "                antecedents = ', '.join(list(rule['antecedents']))",
        "                consequents = ', '.join(list(rule['consequents']))",
        "",
        "                print(f'{i:2d}. {antecedents} → {consequents}')",
        "                print(f'    Soporte: {rule[\"support\"]:.4f} | '",
        "                      f'Confianza: {rule[\"confidence\"]:.4f} | '",
        "                      f'Lift: {rule[\"lift\"]:.4f}')",
        "                print()",
        "",
        "            return frequent_itemsets, rules_sorted",
        "        else:",
        "            print('     Sin reglas con estos umbrales')",
        "            return frequent_itemsets, pd.DataFrame()",
        "",
        "    except Exception as e:",
        "        print(f'    Error en extracción de reglas: {str(e)}')",
        "        return frequent_itemsets, pd.DataFrame()",
        "",
        "# Ejecutar Apriori para el subconjunto relámpago",
        "if len(df_600) > 0:",
        "    frequent_600, rules_600 = ejecutar_apriori(df_600, 'Ajedrez Relámpago')",
        "else:",
        "    print(' Subconjunto vacío')",
        "    frequent_600, rules_600 = pd.DataFrame(), pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Verificación de Hipótesis Específicas",
        "",
        "### Metodología de Verificación",
        "",
        "Se implementará un sistema de verificación estadística para evaluar las siguientes hipótesis:",
        "",
        "1. **H1**: Diferencia de Elo ≥ 1 categoría → Victoria del jugador más fuerte",
        "2. **H2**: Diferencia de Elo ≥ 2 categorías → Victoria del jugador más fuerte",
        "3. **H3**: Ambos jugadores Gran Maestros → Resultado en tablas",
        "4. **H4**: Ambos jugadores Gran Maestros → Victoria de blancas",
        "5. **H5**: Jugadores principiantes/intermedios → Victoria de blancas",
        "6. **H6**: Terminación Normal/Time forfeit según duración de partida",
        "",
        "### Métricas de Evaluación",
        "",
        "Para cada hipótesis se calculará:",
        "- **Soporte**: Frecuencia absoluta de ocurrencia",
        "- **Confianza**: Probabilidad condicional",
        "- **Interpretación**: Validez estadística de la regla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " VERIFICACIÓN SISTEMÁTICA DE HIPÓTESIS\n",
            "================================================================================\n",
            "\n",
            " VERIFICACIÓN: H1: Diferencia ≥1 categoría → Victoria jugador fuerte\n",
            "--------------------------------------------------------------------------------\n",
            "Total de partidas analizadas: 2,452\n",
            "Partidas con diferencia ≥1 categorías: 1,014\n",
            "\n",
            " Análisis - Jugador más fuerte con blancos:\n",
            "   Casos aplicables: 508\n",
            "   Victorias del más fuerte: 349\n",
            "   Soporte: 0.2072\n",
            "   Confianza: 0.6870 (68.7%)\n",
            "   Interpretación: REGLA MODERADA\n",
            "\n",
            " Análisis - Jugador más fuerte con negros:\n",
            "   Casos aplicables: 506\n",
            "   Victorias del más fuerte: 347\n",
            "   Soporte: 0.2064\n",
            "   Confianza: 0.6858 (68.6%)\n",
            "   Interpretación: REGLA MODERADA\n",
            "\n",
            " VERIFICACIÓN: H2: Diferencia ≥2 categorías → Victoria jugador fuerte\n",
            "--------------------------------------------------------------------------------\n",
            "Total de partidas analizadas: 2,452\n",
            "Partidas con diferencia ≥2 categorías: 31\n",
            "\n",
            " Análisis - Jugador más fuerte con blancos:\n",
            "   Casos aplicables: 16\n",
            "   Victorias del más fuerte: 15\n",
            "   Soporte: 0.0065\n",
            "   Confianza: 0.9375 (93.8%)\n",
            "   Interpretación: REGLA FUERTE\n",
            "\n",
            " Análisis - Jugador más fuerte con negros:\n",
            "   Casos aplicables: 15\n",
            "   Victorias del más fuerte: 14\n",
            "   Soporte: 0.0061\n",
            "   Confianza: 0.9333 (93.3%)\n",
            "   Interpretación: REGLA FUERTE\n",
            "\n",
            " VERIFICACIÓN: H3: GM vs GM → Tablas\n",
            "--------------------------------------------------------------------------------\n",
            "Total de partidas: 2,452\n",
            "Partidas GM vs GM: 0\n",
            "  No hay partidas GM vs GM en el subconjunto\n",
            "\n",
            " VERIFICACIÓN: H4: GM vs GM → Victoria blancas\n",
            "--------------------------------------------------------------------------------\n",
            "Total de partidas: 2,452\n",
            "Partidas GM vs GM: 0\n",
            "  No hay partidas GM vs GM en el subconjunto\n"
          ]
        }
      ],
      "source": [
        "# Verificación de hipótesis",
        "def verificar_regla_diferencia_elo(df_subset, diferencia_min, nombre_regla):",
        "    \"\"\"Verifica reglas relacionadas con diferencias de Elo\"\"\"",
        "    print(f'\\n VERIFICACIÓN: {nombre_regla}')",
        "    print('-' * 80)",
        "",
        "    if len(df_subset) == 0:",
        "        print(' Sin datos para verificar')",
        "        return",
        "",
        "    # Filtrar casos con diferencia significativa",
        "    casos_diferencia = df_subset[df_subset['EloDiff_Cat'] >= diferencia_min]",
        "",
        "    print(f'Total de partidas: {len(df_subset):,}')",
        "    print(f'Partidas con diferencia ≥{diferencia_min} categorías: {len(casos_diferencia):,}')",
        "",
        "    if len(casos_diferencia) == 0:",
        "        print('  Casos insuficientes')",
        "        return",
        "",
        "    # Analizar por color del jugador más fuerte",
        "    for color in ['Blanco', 'Negro']:",
        "        casos_color = casos_diferencia[casos_diferencia['JugadorMasFuerte'] == color]",
        "",
        "        if len(casos_color) == 0:",
        "            continue",
        "",
        "        # Determinar resultado esperado",
        "        resultado_esperado = '1-0' if color == 'Blanco' else '0-1'",
        "        casos_ganados = len(casos_color[casos_color['Result'] == resultado_esperado])",
        "",
        "        # Calcular métricas",
        "        soporte = len(casos_color) / len(df_subset)",
        "        confianza = casos_ganados / len(casos_color) if len(casos_color) > 0 else 0",
        "",
        "        print(f'\\n Análisis - Jugador más fuerte con {color.lower()}s:')",
        "        print(f'   Casos válidos: {len(casos_color):,}')",
        "        print(f'   Victorias esperadas: {casos_ganados:,}')",
        "        print(f'   Soporte: {soporte:.4f}')",
        "        print(f'   Confianza: {confianza:.4f} ({confianza*100:.1f}%)')",
        "",
        "        # Interpretación",
        "        if confianza >= 0.7:",
        "            interpretacion = 'REGLA FUERTE'",
        "        elif confianza >= 0.5:",
        "            interpretacion = 'REGLA MODERADA'",
        "        else:",
        "            interpretacion = 'REGLA DÉBIL'",
        "",
        "        print(f'   Interpretación: {interpretacion}')",
        "",
        "def verificar_regla_grandes_maestros(df_subset, resultado_esperado, nombre_regla):",
        "    \"\"\"Verifica reglas específicas para Grandes Maestros\"\"\"",
        "    print(f'\\n VERIFICACIÓN: {nombre_regla}')",
        "    print('-' * 80)",
        "",
        "    # Filtrar partidas donde ambos son Grandes Maestros",
        "    casos_gm = df_subset[",
        "        (df_subset['WhiteElo_Cat'] == 'Gran Maestro') &",
        "        (df_subset['BlackElo_Cat'] == 'Gran Maestro')",
        "    ]",
        "",
        "    print(f'Total de partidas: {len(df_subset):,}')",
        "    print(f'Partidas GM vs GM: {len(casos_gm):,}')",
        "",
        "    if len(casos_gm) == 0:",
        "        print('  Sin partidas GM vs GM')",
        "        return",
        "",
        "    # Análisis por duración de partida",
        "    for categoria in df_subset['MovesCount_Cat'].unique():",
        "        casos_cat = casos_gm[casos_gm['MovesCount_Cat'] == categoria]",
        "",
        "        if len(casos_cat) == 0:",
        "            continue",
        "",
        "        casos_resultado = len(casos_cat[casos_cat['Result'] == resultado_esperado])",
        "",
        "        soporte = len(casos_cat) / len(df_subset)",
        "        confianza = casos_resultado / len(casos_cat) if len(casos_cat) > 0 else 0",
        "",
        "        print(f'\\n Partidas {categoria.lower()}s:')",
        "        print(f'   GM vs GM: {len(casos_cat):,}')",
        "        print(f'   Resultado \"{resultado_esperado}\": {casos_resultado:,}')",
        "        print(f'   Soporte: {soporte:.4f}')",
        "        print(f'   Confianza: {confianza:.4f} ({confianza*100:.1f}%)')",
        "",
        "# Ejecutar todas las verificaciones de hipótesis",
        "print('\\n VERIFICACIÓN SISTEMÁTICA DE HIPÓTESIS')",
        "print('=' * 80)",
        "",
        "if len(df_600) > 0:",
        "    # H1 y H2: Diferencias de Elo",
        "    verificar_regla_diferencia_elo(df_600, 1, 'H1: Diferencia ≥1 categoría → Victoria jugador fuerte')",
        "    verificar_regla_diferencia_elo(df_600, 2, 'H2: Diferencia ≥2 categorías → Victoria jugador fuerte')",
        "",
        "    # H3 y H4: Grandes Maestros",
        "    verificar_regla_grandes_maestros(df_600, '1/2-1/2', 'H3: GM vs GM → Tablas')",
        "    verificar_regla_grandes_maestros(df_600, '1-0', 'H4: GM vs GM → Victoria blancas')",
        "else:",
        "    print(' Sin datos para verificar')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}